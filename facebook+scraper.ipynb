{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# FACEBOOK SCRAPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load/import all dependecies\n",
    "import facebook as fb\n",
    "import _pickle\n",
    "import random\n",
    "import requests\n",
    "import json, csv\n",
    "import pandas as pd\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up token and required variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token = \"EAAWcTS6f2msBAFhFwUhYaEsA69bY6T5cUVt8JjyEMWrXapjluckcAsX1je7M7zOZCfBRKH30cthSzhjQEEC3HFotFMrD0mnSURLhER8VZBWOke2x8zyWLfrnIakJQ8PlrmgTPeZCnL7BZBviagHyQZCKRCPRnbUyEdZCjJa3kKQAZDZD\"\n",
    "## system to read input from other source(ie csv,txt,pkl file)\n",
    "user_id='2165316316832044'\n",
    "page_id='giggsinvetstment'\n",
    "keyword='Using'\n",
    "\n",
    "#load access token\n",
    "graph = fb.GraphAPI(token)\n",
    "#system to directly take input\n",
    "#user_id = input(\"Insert unique User_id here: \")\n",
    "#keyword = input(\"Insert keyword here: \")\n",
    "#page = input(\"Insert unique page name here: \")\n",
    "#print(user_id, keyword, page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Srape data using User_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'name', 'posts', 'likes', 'friends'])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Users posts\n",
    "fb_data = graph.get_object(user_id+'?fields=id,name,posts,likes,friends')\n",
    "fb_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Check if data is scrapped incorrect format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conratulations! The Posts scraping was successfull\n"
     ]
    }
   ],
   "source": [
    "if type(fb_data)==int:\n",
    "    print('Conratulations! The Posts scraping was successfull')\n",
    "elif type(fb_data)!=int:\n",
    "    print('Sorry! We couldn\\'t complete your request')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the User's total number of friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The User's total number of friends are 3053\n"
     ]
    }
   ],
   "source": [
    "friends=fb_data['friends']['summary']['total_count']\n",
    "print('The User\\'s total number of friends are', total_friends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure the posts into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_time</th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-07T16:05:35+0000</td>\n",
       "      <td>2165316316832044_2169791086384567</td>\n",
       "      <td>REAL TALK, I MISS THE LAKE SIDE CITY........ K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-07T16:00:53+0000</td>\n",
       "      <td>2165316316832044_2169786099718399</td>\n",
       "      <td>The only thing limiting you from achieving you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-05T12:12:36+0000</td>\n",
       "      <td>2165316316832044_2166824266681249</td>\n",
       "      <td>looking for a javaScript expert.............</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-02T16:04:58+0000</td>\n",
       "      <td>2165316316832044_2162624007101275</td>\n",
       "      <td>Build, train and evaluate Logistic regression ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-01T18:48:35+0000</td>\n",
       "      <td>2165316316832044_2161249907238685</td>\n",
       "      <td>Perform Sentiment Analysis on tweets with #ken...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_time                                 id  \\\n",
       "0  2018-11-07T16:05:35+0000  2165316316832044_2169791086384567   \n",
       "1  2018-11-07T16:00:53+0000  2165316316832044_2169786099718399   \n",
       "2  2018-11-05T12:12:36+0000  2165316316832044_2166824266681249   \n",
       "3  2018-11-02T16:04:58+0000  2165316316832044_2162624007101275   \n",
       "4  2018-11-01T18:48:35+0000  2165316316832044_2161249907238685   \n",
       "\n",
       "                                             message  \n",
       "0  REAL TALK, I MISS THE LAKE SIDE CITY........ K...  \n",
       "1  The only thing limiting you from achieving you...  \n",
       "2       looking for a javaScript expert.............  \n",
       "3  Build, train and evaluate Logistic regression ...  \n",
       "4  Perform Sentiment Analysis on tweets with #ken...  "
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post=fb_data['posts']['data']\n",
    "post_data = pd.DataFrame(post)\n",
    "post_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if User's posts contain keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User has posts with keyword \" USING \"\n"
     ]
    }
   ],
   "source": [
    "posts=post_data['message']\n",
    "posts_bin= posts.str.contains(keyword, regex=False)\n",
    "if True in posts_bin:\n",
    "    print('User has posts with keyword \"',keyword.upper(),'\"')\n",
    "elif True not in posts_bin:\n",
    "    print('User has no posts with keyword',keyword.upper(),'\"' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out Posts with keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The only thing limiting you from achieving you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Using a deep learning toolkit (\"deepnet\" packa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Statistics Using R-Studio  Training an MLP mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Using Graph Theory to understand Business, Med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#FuelledByPassion   Using R-studio for topic m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Using Jupyter notebook(Python) and cmd for LDA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              message\n",
       "1   The only thing limiting you from achieving you...\n",
       "6   Using a deep learning toolkit (\"deepnet\" packa...\n",
       "7   Statistics Using R-Studio  Training an MLP mod...\n",
       "8   Using Graph Theory to understand Business, Med...\n",
       "9   #FuelledByPassion   Using R-studio for topic m...\n",
       "15  Using Jupyter notebook(Python) and cmd for LDA..."
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs=posts_bin.index[posts_bin==True]\n",
    "post_keyword=pd.DataFrame(posts[rs])\n",
    "post_keyword=post_keyword.replace('\\n','  ',regex=True)\n",
    "post_keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Likes data and re-structure it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_time</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-10-30T09:00:31+0000</td>\n",
       "      <td>191414254890</td>\n",
       "      <td>R bloggers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-10-26T05:24:14+0000</td>\n",
       "      <td>345743205986019</td>\n",
       "      <td>MGF Studio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-10-20T14:42:52+0000</td>\n",
       "      <td>124586014898573</td>\n",
       "      <td>JROz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-02T11:47:01+0000</td>\n",
       "      <td>189185941932956</td>\n",
       "      <td>Queen Bantu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-15T08:49:28+0000</td>\n",
       "      <td>138865793963</td>\n",
       "      <td>African Population and Health Research Center</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_time               id  \\\n",
       "0  2018-10-30T09:00:31+0000     191414254890   \n",
       "1  2018-10-26T05:24:14+0000  345743205986019   \n",
       "2  2018-10-20T14:42:52+0000  124586014898573   \n",
       "3  2018-07-02T11:47:01+0000  189185941932956   \n",
       "4  2018-05-15T08:49:28+0000     138865793963   \n",
       "\n",
       "                                            name  \n",
       "0                                     R bloggers  \n",
       "1                                     MGF Studio  \n",
       "2                                           JROz  \n",
       "3                                    Queen Bantu  \n",
       "4  African Population and Health Research Center  "
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likes=fb_data['likes']['data']\n",
    "likes_data = pd.DataFrame(likes)\n",
    "likes_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       R bloggers\n",
       "1                                       MGF Studio\n",
       "2                                             JROz\n",
       "3                                      Queen Bantu\n",
       "4    African Population and Health Research Center\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_liked = likes_data['name']\n",
    "pages_liked.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Scrape posts using page name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conratulations! The Page was scraping successfull\n"
     ]
    }
   ],
   "source": [
    "pages_post = graph.get_object(page_id+'?fields=id,name,fan_count,new_like_count,location,posts{comments,reactions}')\n",
    "if type(pages_post)==dict:\n",
    "    print('Conratulations! The Page was scraping successfull')\n",
    "#me?fields=id,name,posts{comments,reactions},fan_count,new_like_count,location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure the page results into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Page Name is Giggs Investments and Supplies Limited\n",
      "the Page ID name is 697093603803293\n",
      "the Page Followers is 2\n",
      "the Physical Location is {'latitude': -5.6159858191553, 'longitude': 38.671875}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'name', 'fan_count', 'location', 'posts'])"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check name of page scrapped\n",
    "print('the Page Name is',pages_post['name'])\n",
    "print('the Page ID name is',pages_post['id'])\n",
    "print('the Page Followers is',pages_post['fan_count'])\n",
    "print('the Physical Location is',pages_post['location'])\n",
    "pages_post.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrap data using page unique name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_posts = graph.get_object(page_id+'?fields=posts')\n",
    "pages_posts.keys()\n",
    "k=pages_posts['posts']['data']\n",
    "type(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697093603803293_1017938038385513\n",
      "Now approaching itspre launch is the crawler app. A web marvel for students and researchers alike. Using lemon to make lemonade\n",
      "697093603803293_1017866228392694\n",
      "Data Science\n",
      "Using big data eco-system to get the best out of proccesses/systems\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'message'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-658-16c133bc8445>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'message'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'message'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'message'"
     ]
    }
   ],
   "source": [
    "pp=pages_post['posts']['data']\n",
    "pp=pd.Series(pp)\n",
    "pp.tolist()\n",
    "for p in pp:\n",
    "    if keyword in p['message']:\n",
    "        print(p['id'])\n",
    "        g=print(p['message'])\n",
    "len(g)\n",
    "\n",
    "df.head(5)\n",
    "\n",
    "pb= df['msg'].str.contains(keyword, regex=False)\n",
    "\n",
    "k= pb.index[pb==True]\n",
    "p_keywords=pd.DataFrame(posts[k])\n",
    "p_keywords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRA USER-DEFINED FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## design search function called req_fb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def req_fb(req):\n",
    "    r=requests.get('https://graph.facebook.com/v3.2▾/' + req , {'access_token':token} )\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ind in pages_post['posts']:\n",
    "    if keyword2 in ind:\n",
    "        page_keyword=ind['message']\n",
    "    elif keyword2 not in ind:\n",
    "        print('Page has no post with keyword',keyword2)\n",
    "        \n",
    "print(page_keyword)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
